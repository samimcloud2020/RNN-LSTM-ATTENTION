{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "va4Lx2Jan8il"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Load the text file\n",
        "file_path = \"shakespeare.txt\"  # Change this to your file name\n",
        "\n",
        "# Read all lines\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "# Shuffle the lines (optional, for randomness)\n",
        "random.shuffle(lines)\n",
        "\n",
        "# Calculate the split index\n",
        "split_index = int(0.60 * len(lines))  # 80% training, 20% testing\n",
        "\n",
        "# Split the data\n",
        "train_lines = lines[:split_index]\n",
        "test_lines = lines[split_index:]\n",
        "\n",
        "# Save to new files\n",
        "with open(\"train.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.writelines(train_lines)\n",
        "\n",
        "with open(\"test.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.writelines(test_lines)\n",
        "\n",
        "print(f\"Split complete! Training set: {len(train_lines)} lines, Test set: {len(test_lines)} lines.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiN4oZCYs9TH",
        "outputId": "7253b9e8-476e-4d1b-c103-4ebb0c04c927"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split complete! Training set: 74673 lines, Test set: 49783 lines.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Shakespeare dataset\n",
        "file_path = \"test.txt\"  # Ensure the file is in the correct directory\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    shakespeare_text = f.read()\n",
        "\n",
        "# Preprocess dataset (cleaning)\n",
        "shakespeare_lines = shakespeare_text.split(\"\\n\")\n",
        "shakespeare_lines = [line.strip() for line in shakespeare_lines if len(line) > 10]  # Remove short lines\n"
      ],
      "metadata": {
        "id": "a8Tlx0rRoZIM"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(shakespeare_lines)\n",
        "\n",
        "# Convert text to sequences\n",
        "sequences = tokenizer.texts_to_sequences(shakespeare_lines)\n",
        "vocab_size = len(tokenizer.word_index) + 1  # +1 for padding token\n",
        "\n",
        "# Maximum sequence length\n",
        "max_sequence_length = max(len(seq) for seq in sequences)\n",
        "\n",
        "# Padding sequences\n",
        "sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding=\"pre\")\n",
        "\n",
        "# Split input and target\n",
        "X_train = sequences[:, :-1]  # All words except last\n",
        "y_train = sequences[:, -1]   # Last word (target)\n",
        "\n",
        "# One-hot encode the target output\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=vocab_size)\n"
      ],
      "metadata": {
        "id": "U64M4iGAoZK9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 256  # LSTM units\n",
        "\n",
        "# Define a simple LSTM model\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, latent_dim, input_length=max_sequence_length-1),\n",
        "    LSTM(latent_dim, return_sequences=False),\n",
        "    Dense(vocab_size, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Model Summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "SWPN1xXRoZNs",
        "outputId": "926c3876-51b5-427c-a826-16d99e2c43c3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, batch_size=128, epochs=40)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9uD5TYeoZVQ",
        "outputId": "2acf74b6-b42e-4b41-ad97-1469a6ddf188"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.0122 - loss: 8.5159\n",
            "Epoch 2/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.0291 - loss: 7.4561\n",
            "Epoch 3/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.0497 - loss: 6.9414\n",
            "Epoch 4/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.0634 - loss: 6.3949\n",
            "Epoch 5/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.0813 - loss: 5.9255\n",
            "Epoch 6/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.1069 - loss: 5.4101\n",
            "Epoch 7/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.1445 - loss: 4.9272\n",
            "Epoch 8/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.2022 - loss: 4.4599\n",
            "Epoch 9/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.2734 - loss: 3.9947\n",
            "Epoch 10/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.3603 - loss: 3.5341\n",
            "Epoch 11/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.4345 - loss: 3.1274\n",
            "Epoch 12/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.5047 - loss: 2.7355\n",
            "Epoch 13/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.5696 - loss: 2.3819\n",
            "Epoch 14/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.6260 - loss: 2.0870\n",
            "Epoch 15/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.6776 - loss: 1.8241\n",
            "Epoch 16/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.7254 - loss: 1.5879\n",
            "Epoch 17/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.7655 - loss: 1.3823\n",
            "Epoch 18/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7996 - loss: 1.1938\n",
            "Epoch 19/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8304 - loss: 1.0340\n",
            "Epoch 20/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.8592 - loss: 0.8933\n",
            "Epoch 21/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.8825 - loss: 0.7664\n",
            "Epoch 22/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9019 - loss: 0.6613\n",
            "Epoch 23/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9188 - loss: 0.5697\n",
            "Epoch 24/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9315 - loss: 0.4914\n",
            "Epoch 25/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9396 - loss: 0.4412\n",
            "Epoch 26/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9510 - loss: 0.3721\n",
            "Epoch 27/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.9568 - loss: 0.3275\n",
            "Epoch 28/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9619 - loss: 0.2951\n",
            "Epoch 29/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9652 - loss: 0.2582\n",
            "Epoch 30/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.9685 - loss: 0.2248\n",
            "Epoch 31/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.9706 - loss: 0.2086\n",
            "Epoch 32/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.9697 - loss: 0.1997\n",
            "Epoch 33/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.9730 - loss: 0.1786\n",
            "Epoch 34/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9740 - loss: 0.1606\n",
            "Epoch 35/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9736 - loss: 0.1555\n",
            "Epoch 36/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9739 - loss: 0.1473\n",
            "Epoch 37/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.9743 - loss: 0.1419\n",
            "Epoch 38/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.9738 - loss: 0.1438\n",
            "Epoch 39/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9746 - loss: 0.1322\n",
            "Epoch 40/40\n",
            "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9748 - loss: 0.1293\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7abaf5fca750>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(seed_text, max_length=50, temperature=1.0):\n",
        "    for _ in range(max_length):\n",
        "        sequence = tokenizer.texts_to_sequences([seed_text])\n",
        "        sequence = pad_sequences(sequence, maxlen=max_sequence_length-1, padding=\"pre\")  # Fix: Use \"pre\" padding\n",
        "\n",
        "        predicted_probs = model.predict(sequence, verbose=0)[0]\n",
        "\n",
        "        # Apply temperature sampling\n",
        "        predicted_probs = np.log(predicted_probs + 1e-8) / temperature\n",
        "        predicted_probs = np.exp(predicted_probs) / np.sum(np.exp(predicted_probs))\n",
        "\n",
        "        predicted_index = np.random.choice(range(vocab_size), p=predicted_probs)\n",
        "        predicted_word = tokenizer.index_word.get(predicted_index, \"\")\n",
        "\n",
        "        if not predicted_word:\n",
        "            break\n",
        "\n",
        "        seed_text += \" \" + predicted_word\n",
        "\n",
        "    return seed_text\n"
      ],
      "metadata": {
        "id": "p9u2pcmvoZbb"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(\"AI is fun learning\"))  # Example output: \"To be or not to be, that is the question\"\n",
        "#print(generate_text(\"Shall I compare thee\"))  # Example output: \"Shall I compare thee to a summer's day\"\n",
        "#print(generate_text(\"All the world's a\"))  # Example output: \"All the world's a stage, and all the men and women merely players\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LM2HCAu_oZgr",
        "outputId": "3faf2ea5-08f0-4b55-abee-20d62248bccf"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI is fun learning by antony yourself for't antony i am alone ' i'll be that in my chamber when they are a doing this cat of a thousand rich thrive he heads with myself to come to him to a mouth claudio who horns 'em a interlude man saw cold go to him\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(\"love is good or bad\"))  # Example output: \"Shall I compare thee to a summer's day\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCVNcenNoZmT",
        "outputId": "36b90f62-95c8-44ad-ff7a-a82a9f06b4de"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "love is good or bad circumstances be forc'd you be what no more devil are but to be angel bail myself both never for your promise is meant my lord is boy dead thou for me forswear me for a blanket a i say no no means will me not me not this boy let\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V8NvTc_DoZpw"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LajaqHhyoZqe"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WqT0qTxooZrQ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LumOzp1koZr9"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cNzvWetzoZuI"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HOugKLGUoZ0V"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fML8I4JzoZ7Z"
      },
      "execution_count": 39,
      "outputs": []
    }
  ]
}